---
# Copyright (C) 2023 Robert Wimmer
# SPDX-License-Identifier: GPL-3.0-or-later

# Helm chart version
longhorn_chart_version: "1.6.1"

# Helm release name
longhorn_release_name: "longhorn"

# Helm repository name
longhorn_repo_name: "longhorn"

# Helm chart name
longhorn_chart_name: "{{ longhorn_repo_name }}/{{ longhorn_release_name }}"

# Helm chart URL
longhorn_chart_url: "https://charts.longhorn.io"

# Kubernetes namespace where Longhorn resources should be installed
longhorn_namespace: "longhorn-system"

# By default all tasks that needs to communicate with the Kubernetes
# cluster are executed on your local host (127.0.0.1). But if that one
# doesn't have direct connection to this cluster or should be executed
# elsewhere this variable can be changed accordingly.
longhorn_delegate_to: "127.0.0.1"

# Shows the "helm" command that was executed if a task uses Helm to
# install, update/upgrade or deletes such a resource.
longhorn_helm_show_commands: false

# Without "longhorn_action" variable defined this role will only render a file
# with all the resources that will be installed or upgraded. The rendered
# file with the resources will be called "template.yml" and will be
# placed in the directory specified below. The default will create a directory
# "longhorn/template" in users "$HOME" directory.
longhorn_template_output_directory: "{{ '~/longhorn/template' | expanduser }}"

# The Ansible group name of the nodes where the Longhorn "user components"
# should run. That's mainly the following components:
#
# - Manager
# - Driver Deployer
# - UI
# - ConversionWebhook
# - AdmissionWebhook
# - RecoveryBackend
#
# As the role needs to install a few OS packages on that node, the role
# needs to know on which hosts the tools/packages should be installed.
#
# If Longhorn "system" and "user" components should run on the same nodes
# just put the same group members into "longhorn_nodes_user" and
# "longhorn_nodes_system" group.
#
# This group is also used if you want the role to put a label on the
# group members and/or if a node selector should be used (see below)
# to schedule "user components" only on a specific set of K8s nodes.
longhorn_nodes_user: "k8s_longhorn_user"

# Basically same as above but for "system components". That's basically:
#
# - Instance Manager
# - Engine Image
# - CSI Driver
#
# This group is also used if you want the role to put a label on the
# group members and/or if a node selector should be used (see below)
# to schedule "user components" only on a specific set of K8s nodes.
longhorn_nodes_system: "k8s_longhorn_system"

# Set this to "true" if the Kubernetes nodes defined in the host groups
# specified in "longhorn_nodes_(user|system)" should be labeled. This is
# useful if the Longhorn pods should run only on a specific set of K8s
# hosts. If set to "true" then also "longhorn_node_selector_(user|system)"
# must be specified (see below). The node selector keys and values
# specified there will also be used for the node labels. You can also
# set the labels outside this role of course. In this case leave this
# value to "false" and only set "longhorn_node_selector_(user|system)".
longhorn_label_nodes: false

# If the Longhorn pods should only run on a specific set of nodes with
# specific labels then these labels can be specified here. The keys and
# values defined here are also used to label the nodes in "longhorn_nodes_user"
# group if "longhorn_label_nodes" is set to "true". So make sure that
# the labels are either set somewhere else outside this role or enable
# "longhorn_label_nodes" variable.
#
# For more information what possible consequences it has to run Longhorn
# components only on specific Kubernetes nodes please also read an
# entry in the Longhorn knowledge base:
# Tip: Set Longhorn To Only Use Storage On A Specific Set Of Nodes
# https://longhorn.io/kb/tip-only-use-storage-on-a-set-of-nodes/
#
# This/these node selector(s) will be used for the followning Longhorn
# "user components":
#
# - Manager
# - Driver Deployer
# - UI
# - ConversionWebhook
# - AdmissionWebhook
# - RecoveryBackend
#
# WARNING: Since all Longhorn components will be restarted, the Longhorn
# system is unavailable temporarily. Make sure all Longhorn volumes are
# detached! If there are running Longhorn volumes in the system, this
# means the Longhorn system cannot restart its components and the
# request will be rejected. Donâ€™t operate the Longhorn system while
# node selector settings are updated and Longhorn components are being
# restarted. So it makes very much sense to settle on how the Longhorn
# components should be distributed BEFORE deployment of Longhorn. Changing
# it afterwards is no fun...
#
# Remove the comment (#) in-front of the next two lines to enable the
# setting. The label key "longhorn.user.components" and its value
# "yes" are just examples. You can use whatever valid label key name and
# key value you want of course.
# longhorn_node_selector_user:
#   longhorn.user.components: "yes"

# Basically same as above but for "system components". That's basically:
#
# - Instance Manager
# - Engine Image
# - CSI Driver
#
# longhorn_node_selector_system:
#   longhorn.system.components: "yes"

# Enable multipathd blacklist. For more information see:
# https://longhorn.io/kb/troubleshooting-volume-with-multipath/
# In general it makes normally sense to have these settings enabled.
# longhorn_multipathd_blacklist_directory: "/etc/multipath/conf.d"
# longhorn_multipathd_blacklist_directory_perm: "0755"
# longhorn_multipathd_blacklist_file: "10-longhorn.conf"
# longhorn_multipathd_blacklist_file_perm: "0644"
